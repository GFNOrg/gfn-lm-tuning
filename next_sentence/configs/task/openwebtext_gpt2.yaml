name: "openwebtext"

data:
  path: "data/next_sentence/openwebtext/prompts.txt"
  train_size: 0.95
  limit_prompts: 1000

model:
  name: "gpt2-xl"
  lora_config:
    _target_: peft.LoraConfig
    target_modules: ["c_attn", "c_proj", "c_fc"]
    r: 64
    lora_alpha: 16
    lora_dropout: 0.1
    bias: "none"
    fan_in_fan_out: True

training:
  subtb_lambda: 1.0
  pf_temp_high: 2.0
  pf_temp_low: 0.5
  pf_temp_prob: 0.666
  use_buffer_prob: 0.25
  n_samples: 20
  lr: 0.0001
  accumulate_grad_batches: 25
  epochs: 300
  use_4bit: False

eval:
  n_probes: 10
  diversity_metric: "sequence_embedding"

reward:
  temp_start: 1.0
  temp_end: 0.8
  temp_horizon: 750
  vocab_alpha: -50
  sentence_validator: null
  buffer_size: 50

callbacks:
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val/logP(s) (avg)"
    mode: "max"
    save_last: True
    dirpath: ${save_dir}/checkpoints/${now:%Y-%m-%d}_${now:%H-%M-%S}
    filename: "epoch={epoch:03d}"
    auto_insert_metric_name: True
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "val/logP(s) (avg)"
    mode: "max"
    patience: 10

constraints:
  min_sentence_len: 1
  max_sentence_len: 30
  illegal_tokens: [
    "<|endoftext|>",
    "\n", "\n\n", "\t", "\"", "\"\"", "\"\"\"",
    "http", "https", "://", "www", 
    "Ã‚", "\"?", "?\"",
    "$$", "$$$$",
    "@@", "@@@@", "@@@@@@@@",
    "##", "###", "####", "########", "################", "################################",
    "%%", "%%%%",
    "^", "^^", "^^^^",
    "&&",
    "|", "||", "||||",
    "~", "~~", "~~~~", "~~~~~~~~", "~~~~~~~~~~~~~~~~",
    "!", "!!", "!!!", "!!!!", "!!!!!", "!!!!!!!!",
    "?", "??", '???', "????", "?????", "????????",
    "..", "...", "....", ".....", "......", ".......", "........", ".........", ".............", "................", "..................", "........................", "................................", "................................................................",
    "**", "***", "****", "*****", "********", "************", "****************", "********************************",
    "--", "---", "----", "-----", "------", "-------", "--------", "---------", "----------", "-----------", "------------", "-------------", "--------------", "---------------", "----------------", "--------------------", "------------------------", "--------------------------------", "------------------------------------------------", "--------------------------------------------------------", "----------------------------------------------------------------",
    "==", "===", "====", "======", "========", "============", "================", "================================", "================================================================",
    "__", "___", "____", "_____", "______", "_______", "________", "________________", "________________________", "________________________________", "________________________________________________________________",
    # Abbreviations that have periods in them
    "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z", 
    "US", "Mr", "Mrs", "M", "Ms", "Dr", "Prof", "Jr", "St", "Av",
  ]
